{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "This is the template for the first homework assignment.\n",
    "The only function that you are required to fill in and turn in to Gradescope is \"compute_features\".\n",
    "Please do not edit definition of \"compute_features\" so the Gradescope unit tests run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this code if you want to verify your `sklearn` installation.\n",
    "# If this cell outputs 'array([1])', then it's installed correctly.\n",
    "\n",
    "# from sklearn import tree\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# y = [0, 1]\n",
    "# clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "# clf = clf.fit(X, y)\n",
    "# clf.predict([[2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in training data \n",
    "madelon_x_train = np.load('madelon/train/X_train.npy')\n",
    "madelon_y_train = np.load('madelon/train/y_train.npy')\n",
    "madelon_x_test = np.load('madelon/test/X_test.npy')\n",
    "madelon_y_test = np.load('madelon/test/y_test.npy')\n",
    "\n",
    "# print(madelon_x_train)\n",
    "# print(madelon_y_train)\n",
    "# print(madelon_x_test)\n",
    "# print(madelon_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# When you turn this function in to Gradescope, it is easiest to copy and paste this cell to a new python file called hw1.py\n",
    "# and upload that file instead of the full Jupyter Notebook code (which will cause problems for Gradescope)\n",
    "def compute_features(names):\n",
    "    \"\"\"\n",
    "    Given a list of names of length N, return a numpy matrix of shape (N, 260)\n",
    "    with the features described in problem 2b of the homework assignment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    names: A list of strings\n",
    "        The names to featurize, e.g. [\"albert einstein\", \"marie curie\"]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array:\n",
    "        A numpy array of shape (N, 260)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are not required to use the functions defined below, but they may be useful for you to think about how to structure your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement SGDClassifier model\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def train_and_evaluate_sgd(X_train, y_train, X_test, y_test):\n",
    "    model = SGDClassifier(loss='log', max_iter=10000)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    test_acc=accuracy_score(y_test, pred)\n",
    "    \n",
    "    return model.score(X_train, y_train), test_acc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7552380952380953, 0.65, SGDClassifier(loss='log', max_iter=10000))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate_sgd(madelon_x_train, madelon_y_train, madelon_x_test, madelon_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement Decision Tree and Decision Stump models\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def train_and_evaluate_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    model = DecisionTreeClassifier(criterion='entropy')\n",
    "    model = model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    test_acc=accuracy_score(y_test, pred)\n",
    "    \n",
    "    return model.score(X_train, y_train), test_acc, model\n",
    "\n",
    "\n",
    "def train_and_evaluate_decision_stump(X_train, y_train, X_test, y_test):\n",
    "    model = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    test_acc=accuracy_score(y_test, pred)\n",
    "    \n",
    "    return model.score(X_train, y_train), test_acc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.67, DecisionTreeClassifier(criterion='entropy'))\n",
      "(0.7538095238095238, 0.715, DecisionTreeClassifier(criterion='entropy', max_depth=4))\n"
     ]
    }
   ],
   "source": [
    "print(train_and_evaluate_decision_tree(madelon_x_train, madelon_y_train, madelon_x_test, madelon_y_test))\n",
    "print(train_and_evaluate_decision_stump(madelon_x_train, madelon_y_train, madelon_x_test, madelon_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import numpy as np\n",
    "\n",
    "def train_and_evaluate_sgd_with_stumps(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    stump_outputs = np.empty(shape=(len(X_train),100))\n",
    "    test_outputs = np.empty(shape=(len(X_test),100))\n",
    "    \n",
    "    for i in range (0,100):\n",
    "        feature_set=rd.sample(range(0,len(X_train[0])), k=int(len(X_train[0])/2))\n",
    "        x_train_split=X_train[:,feature_set]\n",
    "        model=DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "        model=model.fit(x_train_split, y_train)\n",
    "        pred=model.predict(x_train_split)\n",
    "        \n",
    "        for j in range (0, len(pred)):\n",
    "            stump_outputs[j,i]=pred[j]\n",
    "        \n",
    "        x_test_split=X_test[:,feature_set]\n",
    "        test_pred = model.predict(x_test_split)\n",
    "        for k in range (0, len(test_pred)):\n",
    "            test_outputs[k,i]=test_pred[k]\n",
    "    \n",
    "    model_final = SGDClassifier(loss='log', max_iter=10000)\n",
    "    model_final = model_final.fit(stump_outputs, y_train)\n",
    "    pred_final = model_final.predict(test_outputs)\n",
    "    \n",
    "    test_acc=accuracy_score(y_test, pred_final)\n",
    "    \n",
    "    return model_final.score(stump_outputs, y_train), test_acc, model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8561904761904762, 0.795, SGDClassifier(loss='log', max_iter=10000))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate_sgd_with_stumps(madelon_x_train, madelon_y_train, madelon_x_test, madelon_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cv_split(fold):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    fold: int\n",
    "        The integer index of the split to load, i.e. 0, 1, 2, 3, or 4\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of 4 numpy arrays that correspond to the following items:\n",
    "        X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_results(sgd_train_acc, sgd_train_std, sgd_heldout_acc, sgd_heldout_std, sgd_test_acc,\n",
    "                 dt_train_acc, dt_train_std, dt_heldout_acc, dt_heldout_std, dt_test_acc,\n",
    "                 dt4_train_acc, dt4_train_std, dt4_heldout_acc, dt4_heldout_std, dt4_test_acc,\n",
    "                 stumps_train_acc, stumps_train_std, stumps_heldout_acc, stumps_heldout_std, stumps_test_acc):\n",
    "    \"\"\"\n",
    "    Plots the final results from problem 2. For each of the 4 classifiers, pass\n",
    "    the training accuracy, training standard deviation, held-out accuracy, held-out\n",
    "    standard deviation, and testing accuracy.\n",
    "\n",
    "    Although it should not be necessary, feel free to edit this method.\n",
    "    \"\"\"\n",
    "    train_x_pos = [0, 4, 8, 12]\n",
    "    cv_x_pos = [1, 5, 9, 13]\n",
    "    test_x_pos = [2, 6, 10, 14]\n",
    "    ticks = cv_x_pos\n",
    "\n",
    "    labels = ['sgd', 'dt', 'dt4', 'stumps (4 x 50)']\n",
    "\n",
    "    train_accs = [sgd_train_acc, dt_train_acc, dt4_train_acc, stumps_train_acc]\n",
    "    train_errors = [sgd_train_std, dt_train_std, dt4_train_std, stumps_train_std]\n",
    "\n",
    "    cv_accs = [sgd_heldout_acc, dt_heldout_acc, dt4_heldout_acc, stumps_heldout_acc]\n",
    "    cv_errors = [sgd_heldout_std, dt_heldout_std, dt4_heldout_std, stumps_heldout_std]\n",
    "\n",
    "    test_accs = [sgd_test_acc, dt_test_acc, dt4_test_acc, stumps_test_acc]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(train_x_pos, train_accs, yerr=train_errors, align='center', alpha=0.5, ecolor='black', capsize=10, label='train')\n",
    "    ax.bar(cv_x_pos, cv_accs, yerr=cv_errors, align='center', alpha=0.5, ecolor='black', capsize=10, label='held-out')\n",
    "    ax.bar(test_x_pos, test_accs, align='center', alpha=0.5, capsize=10, label='test')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title('Models')\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(0.6, 0.1, 0.7, 0.1, 0.1,\n",
    "             0.7, 0.2, 0.7, 0.15, 0.2,\n",
    "             0.8, 0.3, 0.7, 0.2, 0.3,\n",
    "             0.9, 0.4, 0.7, 0.25, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt_predictions(trained_model, X, filename):\n",
    "    \"\"\"\n",
    "    This function will write the predictions txt files needed for your prediction submissions. You can access \n",
    "    your trained model by following the suggested return values in train_and_evaluate_sgd_with_stumps(). You\n",
    "    should also be careful to write the correct filename as described in the write up.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trained_model: sklearn.base.BaseEstimator\n",
    "        These are the sklearn models that you trained above on the training data.\n",
    "    X_leaderboard: np.array\n",
    "        The leaderboard features of shape (N_leaderboard, k)\n",
    "    filename: String\n",
    "        This is the name of the resulting txt file.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    predicted_labels = trained_model.predict(X)\n",
    "    np.savetxt(\"{}.txt\".format(filename), predicted_labels, fmt='%i', newline=\"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
